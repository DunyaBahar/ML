import java.util.List;

public class Perceptron extends SupervisedLearner {
	private DataMatrix featuresOnlyDataMatrix;
	private DataMatrix labelsOnlyDataMatrix;
	
	double[] predictedLabels;

	@Override
	public void train(DataMatrix featuresOnlyDataMatrix, DataMatrix labelsOnlyDataMatrix) throws Exception {
		predictedLabels = new double[ labelsOnlyDataMatrix.getColCount() ] ;
		// The train part of the perceptron algorithm from pg 47 in the book
		// Until all the outputs are correct:
		while (output != target) {
			
			// for each input vector *x*:
			for (int rowIndex = 0; rowIndex < featuresOnlyDataMatrix.getRowCount(); rowIndex++) {
				double net = calculateNet(rowIndex);
				if (activation(net) == true) {
					
				}
			}  // end outer for thru rows in feature matrix

		}  // end while because now outputs = targets

	}

	@Override
	public void predictInstanceLabelsFromFeatures(double[] featureVector, double[] arrayInWhichToPutLabels)
			throws Exception {
		// TODO Auto-generated method stub

	}
	
	private double calculateNet(int rowIndex) {
		double[] inputVector = this.featuresOnlyDataMatrix.matrixData.get(rowIndex);
		// for each input in the input vector:
		double net = 0;
		for (int colIndex = 0; colIndex < featuresOnlyDataMatrix.getColCount(); colIndex++) {
			double input = inputVector[colIndex];
			net += input * weight;
		}  // end inner for thru input vector
		boolean activate;
		activate = true ? net > 0 : false;
	}
	
	// returns true if net is more than 0, false otherwise.
	private boolean activation(double net) {
		return net > 0;
	}

	public DataMatrix getTrainingDataMatrix() {
		return trainingDataMatrix;
	}

	public void setTrainingDataMatrix(DataMatrix trainingDataMatrix) {
		this.trainingDataMatrix = trainingDataMatrix;
	}

	public DataMatrix getLabelsOnlyDataMatrix() {
		return labelsOnlyDataMatrix;
	}

	public void setLabelsOnlyDataMatrix(DataMatrix labelsOnlyDataMatrix) {
		this.labelsOnlyDataMatrix = labelsOnlyDataMatrix;
	}

}
